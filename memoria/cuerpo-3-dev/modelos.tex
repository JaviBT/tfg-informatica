Como ya se adelantó en el capítulo \ref{CAP:SOTA}, los modelos YOLO (\textit{You Only Look Once}) son el estado del arte en la detección de objetos en imágenes y en particular han sido ampliamente utilizados en el contexto de la detección de daños en pavimentos. También se explico que la version más reciente de YOLO es YOLOv8, desarollado por Ultralytics. En esta sección omitimos la explicación de la arquitectura de YOLOv8, ya que se ha explicado en el capítulo \ref{CAP:SOTA} y pasamos a explicar cómo se ha utilizado la libreria de Ultralytics.

Ultralytics ofrece una librería de código abierto que proporciona una implementación de múltiples versiones de los modelos YOLO. En particular, Ultralytics incluye la versión más reciente, YOLOv8 \cite{yolov8_ultralytics}, que es una versión mejorada de YOLOv5 con mejoras en la velocidad, precisión y experiencia de desarrollo. La librería de Ultralytics proporciona una interfaz sencilla para entrenar, evaluar y hacer inferencias con los modelos YOLO.

Para entrenar un modelo YOLO con Ultralytics, primero se necesita un conjunto de datos con imágenes y sus correspondientes anotaciones. Estas anotaciones deben estar en formato COCO, que es un formato estándar para anotaciones de objetos en imágenes. Una vez se tiene el conjunto de datos, se puede entrenar un modelo YOLO con Ultralytics con un solo comando. Ultralytics proporciona una serie de parámetros que se pueden ajustar para personalizar el entrenamiento del modelo, como el tamaño de las imágenes, el número de clases, el número de épocas, etc. Además, Ultralytics proporciona las de métricas de evaluación discutidas en la sección \ref{SEC:METRICAS_ULTRALYTICS} y que se utilizan para evaluar el rendimiento del modelo.
